data:
  train:
    module: torch.utils.data
    class: DataLoader
    DataLoader:
      dataset:
        module: flame.core.data.voc_dataset
        class: VOCDataset
        VOCDataset:
          input_dir: '''../efficient_det_pytorch/dataset/VOC2007/train'''
          image_size: 300
          classes:
            aeroplane: 0
            bicycle: 1
            bird: 2
            boat: 3
            bottle: 4
            bus: 5
            car: 6
            cat: 7
            chair: 8
            cow: 9
            diningtable: 10
            dog: 11
            horse: 12
            motorbike: 13
            person: 14
            pottedplant: 15
            sheep: 16
            sofa: 17
            train: 18
            tvmonitor: 19
          transforms:
            # - iaa.Add(value=(-30, 30), per_channel=True)
            # - iaa.GaussianBlur(sigma=(0, 1))
            # - iaa.MotionBlur()
            # - iaa.JpegCompression(compression=(0, 10))
            - iaa.Fliplr(p=0.5)
            # - iaa.Flipud(p=0.5)
            # - iaa.Grayscale(alpha=(0.0, 0.1))
            # - iaa.Rot90(k=[0, 1, 2, 3], keep_size=False)
            # - iaa.Affine(rotate=(0, 360), shear=(-5, 5), fit_output=True)
            # - iaa.Crop(percent=(0, 0.1))
            # - iaa.Pad(percent=(0, 0.1), keep_size=False)
            # - iaa.ChangeColorTemperature()
          image_pattern: '''*.jpg'''
          label_pattern: '''*.xml'''
      batch_size: 16
      shuffle: True
      collate_fn: 'lambda batch:tuple(zip(*batch))'

  train_eval:
    module: torch.utils.data
    class: DataLoader
    DataLoader:
      dataset:
        module: flame.core.data.voc_dataset
        class: VOCDataset
        VOCDataset:
          input_dir: '''../efficient_det_pytorch/dataset/VOC2007/train'''
          image_size: 300
          classes:
            aeroplane: 0
            bicycle: 1
            bird: 2
            boat: 3
            bottle: 4
            bus: 5
            car: 6
            cat: 7
            chair: 8
            cow: 9
            diningtable: 10
            dog: 11
            horse: 12
            motorbike: 13
            person: 14
            pottedplant: 15
            sheep: 16
            sofa: 17
            train: 18
            tvmonitor: 19
          image_pattern: '''*.jpg'''
          label_pattern: '''*.xml'''
      batch_size: 16
      shuffle: False
      collate_fn: 'lambda batch:tuple(zip(*batch))'

  valid:
    module: torch.utils.data
    class: DataLoader
    DataLoader:
      dataset:
        module: flame.core.data.voc_dataset
        class: VOCDataset
        VOCDataset:
          input_dir: '''../efficient_det_pytorch/dataset/VOC2007/valid'''
          image_size: 300
          classes:
            aeroplane: 0
            bicycle: 1
            bird: 2
            boat: 3
            bottle: 4
            bus: 5
            car: 6
            cat: 7
            chair: 8
            cow: 9
            diningtable: 10
            dog: 11
            horse: 12
            motorbike: 13
            person: 14
            pottedplant: 15
            sheep: 16
            sofa: 17
            train: 18
            tvmonitor: 19
          image_pattern: '''*.jpg'''
          label_pattern: '''*.xml'''
      batch_size: 16
      shuffle: False
      collate_fn: 'lambda batch:tuple(zip(*batch))'

model:
  module: flame.core.model.ssd300_vgg16
  class: SSD300VGG16
  SSD300VGG16:
    num_classes: 20
    pretrained: True
    pretrained_backbone: False

optim:
  module: torch.optim
  class: SGD
  SGD:
    params: config['model'].parameters()
    lr: 0.005
    momentum: 0.95
    weight_decay: 0.0005

train_evaluator:
  module: flame.handlers.metric_evaluator
  class: MetricEvaluator
  MetricEvaluator:
    dataset: config['data']['train_eval']
    device: '''cuda'''

valid_evaluator:
  module: flame.handlers.metric_evaluator
  class: MetricEvaluator
  MetricEvaluator:
    dataset: config['data']['valid']
    device: '''cuda'''

metrics:
  module: flame.handlers.metrics.metrics
  class: Metrics
  Metrics:
    metrics:
      mAP:
        module: flame.handlers.metrics.mAP
        class: mAP
        mAP:
          num_classes: 20
          iou_threshold: 0.5
          box_format: '''corners'''
          output_transform: 'lambda x: (x[0], x[1])'
    attach_to:
      train_evaluator: '''train'''
      valid_evaluator: '''valid'''

screenlogger:
  module: flame.handlers.screenlogger
  class: ScreenLogger
  ScreenLogger:
    eval_names:
      - '''train''' 
      - '''valid'''

history:
  module: flame.handlers.checkpoint
  class: History

checkpoint_loader:
  module: flame.handlers.checkpoint
  class: CheckpointLoader
  CheckpointLoader:
    checkpoint_path: ''''''
    mode: '''train'''

terminate_on_nan:
  module: flame.handlers.terminate_on_nan
  class: TerminateOnNan

lr_scheduler:
  module: flame.handlers.lr_scheduler
  class: ReduceLROnPlateau
  ReduceLROnPlateau:
    score_name: '''mAP'''
    evaluator_name: '''valid_evaluator'''
    mode: '''max'''
    patience: 3
    verbose: True

early_stopping:
  module: flame.handlers.early_stopping
  class: EarlyStopping
  EarlyStopping:
    score_name: '''mAP'''
    evaluator_name: '''valid_evaluator'''
    mode: '''max'''
    patience: 50

best_saver:
  module: flame.handlers.checkpoint
  class: BestSaver
  BestSaver:
    dirname: '''checkpoint/VOC2007/ssd300'''
    score_name: '''mAP'''
    mode: '''max'''
    evaluator_name: '''valid_evaluator'''
    n_saved: 1

backup_saver:
  module: flame.handlers.checkpoint
  class: BackupSaver
  BackupSaver:
    modules:
      - '''model'''
      - '''optim'''
      - '''backup_saver'''
      - '''best_saver'''
      - '''history'''
      - '''lr_scheduler'''
      - '''early_stopping'''
    dirname: '''checkpoint/VOC2007/ssd300'''
    save_interval: 1
    n_saved: 1

engine:
  module: flame.core.engine.engine
  class: Trainer
  Trainer:
    dataset: config['data']['train']
    device: '''cuda'''
    max_epochs: 10000

extralibs:
  torch: torch
  iaa: imgaug.augmenters
